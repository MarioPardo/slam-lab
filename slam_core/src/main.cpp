#include "zmq_bridge.h"
#include "odometry.h"
#include "lidar_processor.h"
#include "occupancy_grid.h"
#include "icp_matcher.h"
#include "feature_extractor.h"
#include "types.h"
#include "PoseGraph.h"
#include <iostream>
#include <csignal>
#include <sstream>
#include <cmath>
#include <vector>
#include <limits>

// Global flag for clean shutdown
volatile sig_atomic_t running = 1;

void signalHandler(int signal) {
    std::cout << "\n[Main] Caught signal " << signal << ", shutting down..." << std::endl;
    running = 0;
}

// Helper function to parse JSON string////

double extractDouble(const std::string& json, const std::string& key) {
    size_t pos = json.find("\"" + key + "\"");
    if (pos == std::string::npos) return 0.0;
    
    pos = json.find(":", pos);
    if (pos == std::string::npos) return 0.0;
    
    size_t start = pos + 1;
    size_t end = json.find_first_of(",}", start);
    
    std::string value = json.substr(start, end - start);
    return std::stod(value);
}

int extractInt(const std::string& json, const std::string& key) {
    size_t pos = json.find("\"" + key + "\"");
    if (pos == std::string::npos) return 0;
    
    pos = json.find(":", pos);
    if (pos == std::string::npos) return 0;
    
    size_t start = pos + 1;
    size_t end = json.find_first_of(",}", start);
    
    std::string value = json.substr(start, end - start);
    return std::stoi(value);
}

std::vector<double> extractDoubleArray(const std::string& json, const std::string& key) {
    std::vector<double> result;
    size_t pos = json.find("\"" + key + "\"");
    if (pos == std::string::npos) return result;
    
    size_t array_start = json.find("[", pos);
    size_t array_end = json.find("]", array_start);
    if (array_start == std::string::npos || array_end == std::string::npos) return result;
    
    std::string array_content = json.substr(array_start + 1, array_end - array_start - 1);
    std::istringstream iss(array_content);
    std::string token;
    
    while (std::getline(iss, token, ',')) {
        try {
            result.push_back(std::stod(token));
        } catch (...) {
            result.push_back(std::numeric_limits<double>::infinity());
        }
    }
    
    return result;
}

slam::OdometryData parseOdometryData(const std::string& message) {
    slam::OdometryData odom;
    
    size_t header_pos = message.find("\"header\"");
    if (header_pos != std::string::npos) {
        odom.timestamp = extractDouble(message, "timestamp");
    }
    
    size_t odom_pos = message.find("\"odometry\"");
    if (odom_pos != std::string::npos) {
        odom.left_encoder = extractDouble(message, "left_encoder");
        odom.right_encoder = extractDouble(message, "right_encoder");
        odom.gyro_z = extractDouble(message, "imu_gyro_z");
        odom.compass_heading = extractDouble(message, "compass_heading");
    }
    
    return odom;
}

slam::LidarScan parseLidarScan(const std::string& message, double timestamp) {
    slam::LidarScan scan;
    
    size_t lidar_pos = message.find("\"lidar\"");
    if (lidar_pos != std::string::npos) {
        scan.timestamp = timestamp;
        scan.count = extractInt(message, "count");
        scan.angle_min = extractDouble(message, "angle_min");
        scan.angle_max = extractDouble(message, "angle_max");
        scan.range_min = extractDouble(message, "range_min");
        scan.range_max = extractDouble(message, "range_max");
        scan.ranges = extractDoubleArray(message, "ranges");
    }
    
    return scan;
}

std::string createVisualizationMessage(
    const std::vector<slam::Pose2D>& odom_trajectory,
    const std::vector<slam::Pose2D>& icp_trajectory,
    const std::vector<slam::Point2D>& lidar_points,
    const std::vector<slam::LineSegment>& extracted_lines,
    const std::vector<slam::Node>& graph_nodes,
    const std::vector<slam::Edge>& graph_edges) {
    
    std::ostringstream viz_data;
    viz_data << "{\"odom_trajectory\": [";
    for (size_t i = 0; i < odom_trajectory.size(); i++) {
        if (i > 0) viz_data << ",";
        viz_data << "{\"x\":" << odom_trajectory[i].x << ",\"y\":" << odom_trajectory[i].y 
                 << ",\"theta\":" << odom_trajectory[i].theta << "}";  // Use raw theta (flipped from before)
    }
    viz_data << "],\"icp_trajectory\":[";
    for (size_t i = 0; i < icp_trajectory.size(); i++) {
        if (i > 0) viz_data << ",";
        viz_data << "{\"x\":" << icp_trajectory[i].x << ",\"y\":" << icp_trajectory[i].y 
                 << ",\"theta\":" << (-icp_trajectory[i].theta - M_PI/2.0) << "}";  // Negate and rotate 90deg CW
    }
    viz_data << "],\"lidar_points\":[";
    for (size_t i = 0; i < lidar_points.size(); i++) {
        if (i > 0) viz_data << ",";
        viz_data << "{\"x\":" << lidar_points[i].x 
                 << ",\"y\":" << lidar_points[i].y << "}";
    }
    viz_data << "],\"extracted_lines\":[";
    for (size_t i = 0; i < extracted_lines.size(); i++) {
        if (i > 0) viz_data << ",";
        viz_data << "{\"start\":{\"x\":" << extracted_lines[i].start.x() 
                 << ",\"y\":" << extracted_lines[i].start.y() 
                 << "},\"end\":{\"x\":" << extracted_lines[i].end.x()
                 << ",\"y\":" << extracted_lines[i].end.y() << "}}";
    }
    viz_data << "],\"pose_graph\":{\"nodes\":[";
    for (size_t i = 0; i < graph_nodes.size(); i++) {
        if (i > 0) viz_data << ",";
        viz_data << "{\"id\":" << graph_nodes[i].id
                 << ",\"x\":"  << graph_nodes[i].pose.x
                 << ",\"y\":"  << graph_nodes[i].pose.y << "}";
    }
    viz_data << "],\"edges\":[";
    for (size_t i = 0; i < graph_edges.size(); i++) {
        if (i > 0) viz_data << ",";
        viz_data << "{\"from\":" << graph_edges[i].from_id
                 << ",\"to\":"   << graph_edges[i].to_id << "}";
    }
    viz_data << "]}}";
    
    return viz_data.str();
}

// gets the edge + center points of a line
std::vector<Eigen::Vector2d> getLinesMainPoints(const std::vector<slam::LineSegment>& lines) {
    std::vector<Eigen::Vector2d> points;
    points.reserve(lines.size() * 3);
    
    for (const auto& line : lines) 
    {
        points.push_back(line.start);
        points.push_back(line.midpoint());
        points.push_back(line.end);
    }
    
    return points;
}

///////

int main(int /*argc*/, char* /*argv*/[]) {
    std::cout << "=== SLAM Core - ZMQ Bidirectional Communication ===" << std::endl;
    
    // Setup signal handling for clean shutdown (Ctrl+C)
    std::signal(SIGINT, signalHandler);
    std::signal(SIGTERM, signalHandler);
    
    try {
        slam::ZMQSubscriber subscriber("tcp://localhost:5555");
        slam::ZMQPublisher publisher("tcp://*:5556");
        
        // TurtleBot parameters
        // Wheel radius: 33mm = 0.033m
        // Wheelbase: 160mm = 0.16m

        //Set up sensor processors
        slam::OdometryProcessor odometry(0.033, 0.16);
        slam::LidarProcessor lidar;
        slam::PoseGraph pose_graph;
        
        // Odom trajectory
        std::vector<slam::Pose2D> odom_trajectory; //keeping for now during development
        slam::Pose2D prev_odom_pose = {0.0, 0.0, 0.0};
        
        // ICP trajectory.  //TODO implement keyframe to reduce error buildup
        std::vector<slam::Pose2D> icp_trajectory;
        slam::Pose2D prev_icp_pose  = {0.0, 0.0, 0.0};
        std::vector<Eigen::Vector2d> prev_point_cloud;
        
        bool first_scan = true;
        
        subscriber.subscribe("robot_state");
        std::cout << "[Main] Waiting for messages... (Press Ctrl+C to exit)" << std::endl;
        std::cout << "[Main] Mode: Odom + Lidar viz | ICP = SHADOW (passive logging)" << std::endl;
        
        int message_count = 0;
        
        // Message callback: odom map + ICP trajectory side-by-side
        auto messageCallback = [&publisher, &odometry, &lidar, &odom_trajectory, &icp_trajectory,
                                 &message_count, &prev_point_cloud, &prev_odom_pose,
                                 &prev_icp_pose, &first_scan, &pose_graph]
                                (const std::string& /*topic*/, const std::string& message)
        {
            message_count++;
            
            try {
                //Odometry
                slam::OdometryData odom = parseOdometryData(message);
                slam::Pose2D curr_odom_pose = odometry.update(odom);

                //Lidar: world-frame points for viz, robot-frame cloud for ICP
                slam::LidarScan scan = parseLidarScan(message, odom.timestamp);
                std::vector<slam::Point2D> world_lidar_points;
                std::vector<Eigen::Vector2d> curr_point_cloud;

                if (!scan.ranges.empty()) {
                    world_lidar_points   = lidar.transformToWorld(scan, curr_odom_pose);
                    curr_point_cloud     = lidar.scanToPointCloud(scan);  // robot frame, for ICP
                }

                //ICP
                slam::Pose2D curr_icp_pose = curr_odom_pose; //icp falls back to odom if issues

                if (!first_scan && !prev_point_cloud.empty() && !curr_point_cloud.empty())
                {
                    slam::Transform2D odom_delta = computePoseDelta(prev_odom_pose, curr_odom_pose);

                    double odom_dx     = odom_delta.translation.x();
                    double odom_dy     = odom_delta.translation.y();
                    double odom_dtheta = std::atan2(odom_delta.rotation(1, 0), odom_delta.rotation(0, 0));

                    // Run ICP: align current scan onto previous scan
                    slam::ICPResult icp = alignPointClouds(
                        prev_point_cloud,  
                        curr_point_cloud,   
                        odom_delta,         // initial guess
                        50,
                        1e-4,
                        0.5
                    );

                    //ICP returns rotation in neg angle (not sure why lol)
                    double raw_angle    = std::atan2(icp.transform.rotation(1, 0), icp.transform.rotation(0, 0));
                    double fixed_angle  = -raw_angle;
                    Eigen::Matrix2d fixed_rotation;
                    fixed_rotation << std::cos(fixed_angle), -std::sin(fixed_angle),
                                      std::sin(fixed_angle),  std::cos(fixed_angle);
                    slam::Transform2D fixed_transform(fixed_rotation, icp.transform.translation);

            
                    curr_icp_pose = prev_icp_pose.transform(fixed_transform);
                }

                //Update states
                if (!curr_point_cloud.empty())
                {
                    prev_point_cloud = curr_point_cloud;
                    prev_odom_pose   = curr_odom_pose;
                    prev_icp_pose    = curr_icp_pose;
                    first_scan       = false;
                }

                //Record both trajectories
                odom_trajectory.push_back(curr_odom_pose);
                icp_trajectory.push_back(curr_icp_pose);

                // Pose graph keyframing
                if (!scan.ranges.empty())
                    pose_graph.tryAddKeyframe(curr_icp_pose, scan, odom.timestamp);

                // Publish: odom map + both trajectories + pose graph
                std::string viz_message = createVisualizationMessage(
                    odom_trajectory, icp_trajectory, world_lidar_points, {},
                    pose_graph.getNodes(), pose_graph.getEdges());
                publisher.publishMessage("visualization", viz_message);

            } catch (const std::exception& e) {
                std::cerr << "[Main] Error: " << e.what() << std::endl;
            }
        };
        
        // Listen for messages
        while (running) {
            subscriber.receiveMessage(messageCallback, 1000); // 1s timeout
        }
        
        std::cout << "[Main] Exiting gracefully" << std::endl;
        std::cout << "[Main] Total messages processed: " << message_count << std::endl;
        
     } catch (const std::exception& e) {
        std::cerr << "[Main] Error: " << e.what() << std::endl;
        return 1;
    }
    
    return 0;
}
